# FontDetector
This is the ML Ops project; a deep-learning based tool that detects which font from a database of fonts, given an image of some characters. 


## Title of project
**FontDetector** is a machine learning system that integrates into existing graphic design or branding workflows to automatically detect fonts from uploaded images. In current industry practice, font matching is done manually or with inconsistent third-party tools. FontDetector improves accuracy and reduces time spent on font identificaiton by using deep learning and image processing. The businesss value lies in improving designer productivity and accuracy, especially in marketing, publishing, and type design work.

Business Metrics:
* Font Identification Accuracy (top-1 and top-3 match)
* Reduction in time spent per font match
* Number of successfal matches without manual intervention
  
<!-- 
Discuss: Value proposition: Your will propose a machine learning system that can be 
used in an existing business or service. (You should not propose a system in which 
a new business or service would be developed around the machine learning system.) 
Describe the value proposition for the machine learning system. What’s the (non-ML) 
status quo used in the business or service? What business metric are you going to be 
judged on? (Note that the “service” does not have to be for general users; you can 
propose a system for a science problem, for example.)
-->

### Contributors

<!-- Table of contributors and their roles. 
First row: define responsibilities that are shared by the team. 
Then, each row after that is: name of contributor, their role, and in the third column, 
you will link to their contributions. If your project involves multiple repos, you will 
link to their contributions in all repos here. -->

| Name                            | Responsible for | Link to their commits in this repo |
|---------------------------------|-----------------|------------------------------------|
| All team members                |                 |                                    |
| Team member 1: Mukund Ramakrishnan                   |         |        *To be added*                            |
| Team member 2: Alex Gonzalez                   |              |            *To be added*                        |
| Team member 3: Austin Ebel                  |                 |         *To be added*                           |

## List of Responsibilites we have:
* Model development
*  data pipeline
*   deployment
* Data collection
*  training pipeline
* synthetic data generation
*  backend setup
* model serving
* frontend uploader integration


### System diagram

<!-- Overall digram of system. Doesn't need polish, does need to show all the pieces. 
Must include: all the hardware, all the containers/software platforms, all the models, 
all the data. -->

### Summary of outside materials

<!-- In a table, a row for each dataset, foundation model. 
Name of data/model, conditions under which it was created (ideally with links/references), 
conditions under which it may be used. -->

|              | How it was created | Conditions of use |
|--------------|--------------------|-------------------|
| Data set 1: Adobe VFR Font Set   | Adobe created this dataset as part of their Visual Font Recognition (VFR) research. It includes labeled images of real-world font renderings collected from diverse sources and manually annotated for font classification                    |     Adobe VFR is publicly released for non-commercial, academic use only.              |
| Data set 2: Google Fonts (Rendered Synthetic Images)   | This dataset was synthetically generated by rendering sample text using fonts from the Google Fonts open-source library. Each font was applied to a predefined string using a Python script with PIL to generate consistent labeled training images                    |   All fonts in the Google Fonts library are licensed under open-source licenses. The generated images are free to use for commerical and academic purposes as long as the original font licenses are respected.                |
| Base model 1: ResNet18 |  ResNet18 is a convolutional neural network architecture pretrained on the ImageNet dataset. It was adapted to the font classification task through transfer learning by fine-tuning it on the font image datasets.                  | ResNet18 is available under an open-source license (MIT License) and can be used freely for both academic and commerical projects.                   |
| etc          |                    |                   |


### Summary of infrastructure requirements

<!-- Itemize all your anticipated requirements: What (`m1.medium` VM, `gpu_mi100`), 
how much/when, justification. Include compute, floating IPs, persistent storage. 
The table below shows an example, it is not a recommendation. -->

| Requirement     | How many/when                                     | Justification |
|-----------------|---------------------------------------------------|---------------|
| `m1.medium` VMs | 3 for entire project duration                     | For Backend services, model orchestration, and frontent           |
| `gpu_mi100`     | 4 hour block twice a week                         |  For model training and fine-tuning on image data             |
| Floating IPs    | 1 for entire project duration, 1 for sporadic use |      To host the frontend uploader + model inference API         |
| *Volume Storage*     (unsure)        |           50GB persistent Volume                                        |        To store datasets and model checkpoints       |

### Detailed design plan

<!-- In each section, you should describe (1) your strategy, (2) the relevant parts of the 
diagram, (3) justification for your strategy, (4) relate back to lecture material, 
(5) include specific numbers. -->

#### Model training and training platforms
**Strategy**: We will use transfer learning by fine-tuning a pretrained **ResNet18** model on our font classification datasets. The datasets include Adobe VFR and syntehtic Google Fonts rendered via a Python pipeline. Training will include data augmentation to increase robustness.

**Diagram Components:**
* Datasets stored in Chameleon persistent volume
* ResNet18 fine-tuned in a GPU container (PytTorch)
* MLflow for experiment tracking
* Ray cluster for job scheduling and parallel experiments

**Justification:**
This approach balances performance and speed. ResNet18 provides good results with manageable training times. Training on both syntehtic and real data improves generalization. training on Chameleon using Ray allows scheduling and reproducibility.

**Lecture Tie-Ins:**
* Unit 4: Transfer Learning, scale with Ray
* Unit 5: Infrastructure provisioning and containerization
* Difficulty Point: ?

**Numbers:**
* Training time per run: ? (GPU)
* Dataset size: ~25,000 images
* Target: >= 90% top-1 accuracy
* Tuning parameters: learning rate, batch size, dropout, augmentation strength
  
<!-- Make sure to clarify how you will satisfy the Unit 4 and Unit 5 requirements, 
and which optional "difficulty" points you are attempting. -->

#### Model serving and monitoring platforms
**Strategy:** The model will be wrapped in a **FastAPI service** and served via an inference container. We will expsoe a REST endpoint (/predict) that accepts image uploads and returns the top-1 font predicitons. Monitoring will be done via...

**Diagram Components:**
* Model Continer (FastAPI)
* REST API
* Frontend image uploader connected to API
* metrics...

**Justification:**
FastAPI is fast and lightweight for real-time inference. 

**Lecture Tie-Ins:**
* Unit 6: Containerized API serving, latency analysis
* Unit 7: Monitering with
* Difficulty Point: ?

**Metrics:**
* Inference latency target: <300ms per request
* Throughput: ~10-20 concurrent requests?
* Serving from both CPU and GPU environments will be benchmarked

<!-- Make sure to clarify how you will satisfy the Unit 6 and Unit 7 requirements, 
and which optional "difficulty" points you are attempting. -->

#### Data pipeline

<!-- Make sure to clarify how you will satisfy the Unit 8 requirements,  and which 
optional "difficulty" points you are attempting. -->

#### Continuous X

<!-- Make sure to clarify how you will satisfy the Unit 3 requirements,  and which 
optional "difficulty" points you are attempting. -->

